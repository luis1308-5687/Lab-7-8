{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c94d67",
   "metadata": {},
   "source": [
    "NOMBRE: LRCQ                                                    CARRERA:CICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "class RoboticArmEnv(gym.Env):\n",
    "    def _init_(self, render_mode=None):\n",
    "        super()._init_()\n",
    "        self.render_mode = render_mode\n",
    "        self.observation_space = spaces.Box(low=-1.0, high=1.0, shape=(6,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32)\n",
    "        self.physics_client = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if self.physics_client is not None:\n",
    "            p.disconnect(self.physics_client)\n",
    "        self.physics_client = p.connect(p.GUI if self.render_mode == \"human\" else p.DIRECT)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.resetSimulation()\n",
    "        p.setGravity(0, 0, -9.8)\n",
    "        p.loadURDF(\"plane.urdf\")\n",
    "        self.arm_id = p.loadURDF(\"kuka_iiwa/model.urdf\", useFixedBase=True)\n",
    "        self.cup_id = p.loadURDF(\"cube_small.urdf\", [np.random.uniform(0.3, 0.7), 0, 0.05])\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        joint_states = p.getJointStates(self.arm_id, [0, 1, 2])\n",
    "        joints = np.array([s[0] for s in joint_states])\n",
    "        cup_pos, _ = p.getBasePositionAndOrientation(self.cup_id)\n",
    "        return np.concatenate((joints, np.array(cup_pos[:3])), axis=0)\n",
    "\n",
    "    def step(self, action):\n",
    "        for i in range(3):\n",
    "            p.setJointMotorControl2(self.arm_id, i, p.POSITION_CONTROL, targetPosition=action[i])\n",
    "        p.stepSimulation()\n",
    "        time.sleep(1/60.0)\n",
    "        obs = self._get_obs()\n",
    "        reward = -0.01\n",
    "        done = False\n",
    "        cup_pos, _ = p.getBasePositionAndOrientation(self.cup_id)\n",
    "        if cup_pos[2] < 0.02:\n",
    "            reward = -1.0\n",
    "            done = True\n",
    "        elif abs(cup_pos[0] - 0.5) < 0.05:\n",
    "            reward = 1.0\n",
    "            done = True\n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        if self.physics_client:\n",
    "            p.disconnect(self.physics_client)\n",
    "            self.physics_client = None\n",
    "\n",
    "\n",
    "# ENTRENAMIENTO\n",
    "env = RoboticArmEnv(render_mode=None)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(\"ppo_robot_arm\")\n",
    "env.close()\n",
    "\n",
    "# EVALUACIÃ“N\n",
    "env = RoboticArmEnv(render_mode=\"human\")\n",
    "model = PPO.load(\"ppo_robot_arm\")\n",
    "obs, _ = env.reset()\n",
    "for _ in range(200):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    if done:\n",
    "        print(f\"Episode finished with reward: {reward}\")\n",
    "        obs, _ = env.reset()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
